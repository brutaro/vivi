#!/usr/bin/env python3
"""
Agente de Busca com Gemini 2.5 Flash como Redator
Fluxo: Pergunta ‚Üí Pinecone ‚Üí Documentos ‚Üí Gemini ‚Üí Resposta Formal + Refer√™ncias
Integrado com a persona da Vivi IA - Especialista em SIAPE e Gest√£o P√∫blica
"""

import os
import google.generativeai as genai
from pinecone import Pinecone
import json
import random

class AgenteBuscaGemini:
    def __init__(self):
        """Inicializa o agente"""
        # Configurar Pinecone (vers√£o 7.3.0)
        self.pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
        self.index = self.pc.Index(os.getenv("PINECONE_INDEX", "vivi-ia-base"))
        
        # Configurar Gemini
        genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # Catchphrases da Vivi IA
        self.catchphrases = {
            "abertura": [
                "Vamos ao que interessa...",
                "Analisando os dados enviados...",
                "Olha s√≥ o que temos aqui...",
                "Vamos conferir se est√° nos conformes..."
            ],
            "positivo": [
                "Procedimento correto. Seguindo em frente.",
                "Tudo nos conformes, sem ressalvas.",
                "Aqui temos um exemplo de boa gest√£o documental."
            ],
            "negativo": [
                "Temos um problema aqui...",
                "Isso n√£o bate com as normativas. Vamos corrigir.",
                "Estamos diante de um caso que precisa de ajustes."
            ]
        }
        
        print("ü§ñ Agente de Busca Vivi IA com Gemini 2.5 Flash inicializado!")

    def gerar_embedding(self, texto):
        """Gera embedding usando modelo integrado do Pinecone (llama-text-embed-v2)"""
        try:
            # Usar o modelo integrado do Pinecone que gera 1024 dimens√µes
            response = self.pc.inference.embed(
                model="llama-text-embed-v2",
                inputs=[texto],
                parameters={"input_type": "passage"}
            )
            return response.data[0]['values']
        except Exception as e:
            print(f"‚ùå Erro ao gerar embedding: {e}")
            return None

    def buscar_no_pinecone(self, pergunta, top_k=10):
        """Busca sem√¢ntica no Pinecone"""
        print(f"üîç Buscando no Pinecone: '{pergunta}'")

        try:
            # Gerar embedding usando modelo integrado do Pinecone
            embedding = self.gerar_embedding(pergunta)
            if embedding is None:
                print("‚ùå Erro ao gerar embedding")
                return []

            # Buscar usando query no namespace vazio (onde est√£o os dados)
            results = self.index.query(
                namespace="",
                vector=embedding,
                top_k=top_k,
                include_metadata=True
            )

            if hasattr(results, 'matches') and results.matches:
                matches = results.matches
                print(f"‚úÖ {len(matches)} documentos encontrados")
                return matches
            else:
                print("‚ö†Ô∏è Nenhum resultado encontrado")
                return []

        except Exception as e:
            print(f"‚ùå Erro na busca Pinecone: {e}")
            return []
    
    def limpar_e_corrigir_texto(self, texto):
        """Limpa e corrige automaticamente erros de texto"""
        # Corre√ß√µes obrigat√≥rias
        correcoes = {
            'escontado': 'descontado',
            'ESCONTADO': 'DESCONTADO',
            'chunk': 'documento',
            'chunks': 'documentos',
            'Chunk': 'Documento',
            'Chunks': 'Documentos',
            'Abate do Teto Constitucional': 'Abate Teto Constitucional',
            'ABATE DO TETO CONSTITUCIONAL': 'ABATE TETO CONSTITUCIONAL',
            'Minist√©rio da Economia': 'Minist√©rio da Gest√£o e Inova√ß√£o em Servi√ßos P√∫blicos (MGI)',
            'MINIST√âRIO DA ECONOMIA': 'MINIST√âRIO DA GEST√ÉO E INOVA√á√ÉO EM SERVI√áOS P√öBLICOS (MGI)',
            'Minist√©rio da Infraestrutura': 'Minist√©rio do Trabalho (MT)',
            'MINIST√âRIO DA INFRAESTRUTURA': 'MINIST√âRIO DO TRABALHO (MT)'
        }

        texto_limpo = texto
        for erro, correcao in correcoes.items():
            texto_limpo = texto_limpo.replace(erro, correcao)

        return texto_limpo

    def preparar_contexto_para_gemini(self, documentos):
        """Prepara o contexto dos documentos para o Gemini"""
        contexto = []

        for i, doc in enumerate(documentos):
            if hasattr(doc, 'metadata') and doc.metadata:
                metadata = doc.metadata
                # Na vers√£o 7.3.0, o conte√∫do pode estar em diferentes campos
                conteudo = metadata.get('text', '') or metadata.get('content', '') or metadata.get('chunk_text', '')
                document_title = metadata.get('document_title', metadata.get('source', f'Documento {i+1}'))

                if conteudo:
                    # Limpar texto (remover caracteres especiais)
                    chunk_clean = conteudo.replace('\uf0c9', '').replace('\uf002', '').replace('\uf142', '')
                    chunk_clean = ' '.join(chunk_clean.split())  # Normalizar espa√ßos

                    # Aplicar corre√ß√µes autom√°ticas
                    chunk_clean = self.limpar_e_corrigir_texto(chunk_clean)

                    contexto.append({
                        "documento_id": doc.id if hasattr(doc, 'id') else f'doc_{i}',
                        "document_title": document_title,
                        "relevancia": f"{doc.score:.2%}" if hasattr(doc, 'score') else "N/A",
                        "conteudo": chunk_clean[:5000] + "..." if len(chunk_clean) > 5000 else chunk_clean
                    })

        return contexto

    def processar_com_gemini(self, pergunta, documentos):
        """Processa a pergunta e documentos com Gemini usando persona da Vivi IA"""
        print("ü§ñ Gerando resposta com Gemini 2.5 Flash (Vivi IA)...")

        if not documentos:
            return "‚ùå Nenhum resultado encontrado no banco de dados."

        # Preparar contexto
        contexto = self.preparar_contexto_para_gemini(documentos)

        # Selecionar catchphrase aleat√≥ria
        catchphrase = random.choice(self.catchphrases["abertura"])

        # Prompt da Vivi IA - VERS√ÉO REFOR√áADA
        prompt = f"""
VOC√ä √â VIVI IA. A PARTIR DE AGORA, VOC√ä √â ELA COMPLETAMENTE.

INSTRU√á√ïES DE PERSONALIDADE (OBRIGAT√ìRIAS):
- VOC√ä SEMPRE fala na primeira pessoa como "eu" (Vivi)
- SUA primeira frase DEVE SER EXATAMENTE a catchphrase fornecida: "{catchphrase}"
- VOC√ä √© DIRETA, EFICIENTE, COMPETENTE e PROFISSIONAL
- VOC√ä √© INTOLERANTE com pregui√ßa e falta de esfor√ßo
- VOC√ä √© CORDIAL mas FIRME quando necess√°rio
- VOC√ä √© especialista em gest√£o p√∫blica e SIAPE

EXEMPLO DE ABERTURA:
"{catchphrase}"

Agora responda √† pergunta mantendo esta personalidade.

PERGUNTA DO USU√ÅRIO:
{pergunta}

CONTEXTO DISPON√çVEL (documentos do documento):
{json.dumps(contexto, indent=2, ensure_ascii=False)}

INSTRU√á√ïES DE RESPOSTA:
1. COMECE SUA RESPOSTA com EXATAMENTE esta frase: "{catchphrase}"
2. RESPONDA NA PRIMEIRA PESSOA como Vivi IA
3. Seja DIRETA e OBJETIVA, mas PROFISSIONAL
4. Use linguagem FORMAL e T√âCNICA quando necess√°rio
5. N√ÉO cite refer√™ncias inline (documento_id) ao longo do texto
6. Se n√£o houver informa√ß√£o suficiente, diga claramente
7. N√ÉO invente informa√ß√µes que n√£o estejam no contexto
8. Estruture a resposta para facilitar a compreens√£o
9. Use CAPSLOCK para √äNFASE em normativas relevantes
10. Seja ASSERTIVA e OBJETIVA

PERSONALIDADE VIVI IA:
- Competente, Direta, Eficiente, Cordial, Justa, Inteligente
- Impaciente com a falta de esfor√ßo
- Tom profissional e objetivo, sem ser rude
- Respeito sempre, mas sem tolerar desorganiza√ß√£o

IMPORTANTE SOBRE CONCLUS√ÉO:
- ANTES das refer√™ncias, SEMPRE fa√ßa uma conclus√£o sucinta
- A conclus√£o deve ser na primeira pessoa como Vivi IA
- Deve refor√ßar a import√¢ncia da informa√ß√£o ou orientar sobre pr√≥ximos passos
- Deve ser breve (2-3 frases) e manter o tom profissional mas pessoal da Vivi IA
- Exemplos: "Espero que estas informa√ß√µes sejam √∫teis para sua gest√£o.", "Fique atento √†s normativas espec√≠ficas do seu caso.", "Esta √© uma quest√£o que merece aten√ß√£o especial."

IMPORTANTE SOBRE REFER√äNCIAS:
- N√ÉO use refer√™ncias inline como "documento_id: abate_teto#5"
- Ap√≥s a conclus√£o, adicione uma se√ß√£o "Refer√™ncias:"
- Use APENAS os metadados document_title dos documentos que voc√™ realmente utilizou para construir a resposta
- N√ÉO invente t√≠tulos de documentos - use APENAMENTE os t√≠tulos reais dos metadados
- IMPORTANTE: Sempre cite TODAS as refer√™ncias consultadas, tanto o documento principal quanto todos os documentos complementares que foram utilizados para enriquecer a resposta
- SEMPRE liste TODOS os documentos complementares que foram utilizados para enriquecer a resposta, mesmo que n√£o sejam o documento principal consultado

IMPORTANTE SOBRE LISTAS E INFORMA√á√ïES COMPLETAS:
- Quando a pergunta solicitar uma lista (bancos, √≥rg√£os, processos, etc.), forne√ßa TODOS os itens dispon√≠veis no contexto
- N√ÉO use express√µes como "alguns dos", "entre outros", "dentre os quais" - seja COMPLETO
- Liste TODOS os itens encontrados, organizando-os de forma clara e leg√≠vel
- Se houver muitos itens, use formata√ß√£o adequada (t√≥picos, tabelas, etc.)
- EXEMPLO: ‚ùå "Alguns bancos: Banco A, Banco B, entre outros" | ‚úÖ "Bancos credenciados: Banco A, Banco B, Banco C, Banco D"

INSTRU√á√ïES ESPEC√çFICAS PARA LISTAS ESTRUTURADAS:
- Para listas com metadados estruturados (bancos, √≥rg√£os, processos, etc.), SEMPRE inclua TODAS as informa√ß√µes dispon√≠veis
- N√ÉO omita nenhuma informa√ß√£o - se estiver no contexto, deve aparecer na resposta
- Se uma informa√ß√£o n√£o estiver dispon√≠vel, indique claramente "N√£o especificado" ou "N√£o dispon√≠vel"
- Organize a lista de forma sistem√°tica e consistente para todos os itens
- Use formata√ß√£o padronizada (s√≠mbolos, espa√ßamento, estrutura)
- EXEMPLOS CORRETOS:
  ‚Ä¢ Bancos: "001 - BANCO DO BRASIL S.A. ‚óã Ponto Focal: Nome Completo ‚óã E-mail: email@banco.com ‚óã Telefone: (XX) XXXX-XXXX"
  ‚Ä¢ √ìrg√£os: "√ìRG√ÉO A - Nome do √ìrg√£o ‚óã Respons√°vel: Nome ‚óã Departamento: Setor ‚óã Contato: email@orgao.gov.br"
  ‚Ä¢ Processos: "PROCESSO 001 - Descri√ß√£o ‚óã Prazo: X dias ‚óã Respons√°vel: Nome ‚óã Status: Em andamento"

CORRE√á√ïES OBRIGAT√ìRIAS DE PALAVRAS:
- SEMPRE substitua "chunks" por "documentos"
- SEMPRE substitua "escontado" por "descontado"
- SEMPRE substitua "chunk_id" por "documento_id"
- SEMPRE substitua "chunk" por "documento"
- SEMPRE substitua "chunks" por "documentos"
- SEMPRE substitua "chunk_text" por "conte√∫do do documento"
- SEMPRE substitua "chunk_index" por "√≠ndice do documento"
- SEMPRE substitua "chunk_size" por "tamanho do documento"
- SEMPRE substitua "Abate do Teto Constitucional" por "Abate Teto Constitucional"
- SEMPRE substitua "Minist√©rio da Economia" por "Minist√©rio da Gest√£o e Inova√ß√£o em Servi√ßos P√∫blicos (MGI)"
- SEMPRE substitua "Minist√©rio da Infraestrutura" por "Minist√©rio do Trabalho (MT)"

EXEMPLOS DE CORRE√á√ÉO:
‚ùå INCORRETO: "os chunks encontrados", "escontado no contracheque", "Abate do Teto Constitucional", "Minist√©rio da Economia"
‚úÖ CORRETO: "os documentos encontrados", "descontado no contracheque", "Abate Teto Constitucional", "Minist√©rio da Gest√£o e Inova√ß√£o em Servi√ßos P√∫blicos (MGI)"

IMPORTANTE: SUA RESPOSTA DEVE come√ßar EXATAMENTE com: "{catchphrase}"

AGORA RESPONDA COMO VIVI IA:
"""

        try:
            response = self.model.generate_content(prompt)
            resposta = response.text

            # Mostrar documentos encontrados (debug)
            print(f"\nüìö DOCUMENTOS ENCONTRADOS:")
            for i, ctx in enumerate(contexto):
                print(f"\n--- Documento {i+1} ---")
                print(f"ID: {ctx['documento_id']}")
                print(f"T√≠tulo: {ctx['document_title']}")
                print(f"Relev√¢ncia: {ctx['relevancia']}")
                print(f"Conte√∫do (CORRIGIDO): {ctx['conteudo'][:150]}...")

            return resposta

        except Exception as e:
            print(f"‚ùå Erro no Gemini: {e}")
            return f"Erro ao processar com IA: {str(e)}"
    
    def executar_busca_completa(self, pergunta):
        """Executa a busca completa"""
        print(f"\nüéØ EXECUTANDO BUSCA COMPLETA - VIVI IA")
        print(f"üìù Pergunta: {pergunta}")
        print("=" * 60)
        
        # 1. Buscar no Pinecone
        documentos = self.buscar_no_pinecone(pergunta)
        
        # 2. Processar com Gemini
        resposta = self.processar_com_gemini(pergunta, documentos)
        
        print("‚úÖ Busca completa finalizada!")
        return resposta

if __name__ == "__main__":
    # Teste simples
    agente = AgenteBuscaGemini()
    resposta = agente.executar_busca_completa("Como funciona o SIAPE?")
    print(resposta)
